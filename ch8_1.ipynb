{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "max_features=10000\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_features)\n",
    "print(type(x_train));print(type(x_test))\n",
    "print(type(y_train));print(type(y_test))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 12500, 1: 12500}\n",
      "{0: 12500, 1: 12500}\n"
     ]
    }
   ],
   "source": [
    "unique,count=np.unique(y_train,return_counts=True)\n",
    "print(dict(zip(unique,count)))\n",
    "unique,count=np.unique(y_test,return_counts=True)\n",
    "print(dict(zip(unique,count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "218\n",
      "88584\n",
      "<class 'dict'>\n",
      "lacks\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(len(x_train[0]))\n",
    "wordindex=imdb.get_word_index()\n",
    "print(len(wordindex))\n",
    "print(type(wordindex))\n",
    "for key,value in wordindex.items():\n",
    "    if value==1500:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!thisfilmwasjustbrilliantcastinglocationscenerystorydirectioneveryone'sreallysuitedtheparttheyplayedandyoucouldjustimaginebeingthererobert!isanamazingactorandnowthesamebeingdirector!fathercamefromthesamescottishislandasmyselfsoilovedthefacttherewasarealconnectionwiththisfilmthewittyremarksthroughoutthefilmweregreatitwasjustbrilliantsomuchthatiboughtthefilmassoonasitwasreleasedfor!andwouldrecommendittoeveryonetowatchandtheflyfishingwasamazingreallycriedattheenditwassosadandyouknowwhattheysayifyoucryatafilmitmusthavebeengoodandthisdefinitelywasalso!tothetwolittleboy'sthatplayedthe!ofnormanandpaultheywerejustbrilliantchildrenareoftenleftoutofthe!listithinkbecausethestarsthatplaythemallgrownuparesuchabigprofileforthewholefilmbutthesechildrenareamazingandshouldbepraisedforwhattheyhavedonedon'tyouthinkthewholestorywassolovelybecauseitwastrueandwassomeone'slifeafterallthatwassharedwithusall\n"
     ]
    }
   ],
   "source": [
    "exchindex=dict([(value,key) for (key,value) in wordindex.items()])\n",
    "review=''.join([exchindex.get(i-3,'!') for i in x_train[0]])\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 700)\n",
      "(25000, 700)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "lenmax=700\n",
    "input_train=sequence.pad_sequences(x_train,maxlen=lenmax)\n",
    "input_test=sequence.pad_sequences(x_test,maxlen=lenmax)\n",
    "print(input_train.shape)\n",
    "print(input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 21s 851us/step - loss: 0.5341 - acc: 0.7275\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 21s 859us/step - loss: 0.3490 - acc: 0.8575\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 21s 857us/step - loss: 0.2900 - acc: 0.8850\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 21s 857us/step - loss: 0.2506 - acc: 0.9034\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 21s 853us/step - loss: 0.2241 - acc: 0.9154\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 21s 857us/step - loss: 0.1934 - acc: 0.9275\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 22s 863us/step - loss: 0.1715 - acc: 0.9380\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 22s 862us/step - loss: 0.1449 - acc: 0.9477\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 22s 861us/step - loss: 0.1191 - acc: 0.9572\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 21s 859us/step - loss: 0.0957 - acc: 0.9662\n",
      "25000/25000 [==============================] - 14s 559us/step\n",
      "25000/25000 [==============================] - 14s 556us/step\n",
      "[0.14247505063295365, 0.9520000219345093]\n",
      "[0.47568165253162387, 0.7996000051498413]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Embedding, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "srnn=Sequential()\n",
    "srnn.add(Embedding(max_features,32))\n",
    "srnn.add(SimpleRNN(32))\n",
    "srnn.add(Dense(1,activation='sigmoid'))\n",
    "srnn.summary()\n",
    "srnn.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "srnn.fit(input_train,y_train,epochs=10,batch_size=128)\n",
    "train_loss_acc=srnn.evaluate(input_train,y_train)\n",
    "test_loss_acc=srnn.evaluate(input_test,y_test)\n",
    "print(train_loss_acc)\n",
    "print(test_loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.4815 - acc: 0.7818\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2880 - acc: 0.8852\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2350 - acc: 0.9118\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2021 - acc: 0.9251\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1841 - acc: 0.9311\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1635 - acc: 0.9416\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1539 - acc: 0.9459\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1415 - acc: 0.9509\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1337 - acc: 0.9521\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 53s 2ms/step - loss: 0.1278 - acc: 0.9550\n",
      "25000/25000 [==============================] - 31s 1ms/step\n",
      "25000/25000 [==============================] - 28s 1ms/step\n",
      "[0.10286183683037758, 0.9681199789047241]\n",
      "[0.4097904998731613, 0.8678399920463562]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "m_lstm=Sequential()\n",
    "m_lstm.add(Embedding(max_features,32))\n",
    "m_lstm.add(LSTM(32))\n",
    "m_lstm.add(Dense(1,activation='sigmoid'))\n",
    "m_lstm.summary()\n",
    "m_lstm.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "m_lstm.fit(input_train,y_train,epochs=10,batch_size=128)\n",
    "train_loss_acc=m_lstm.evaluate(input_train,y_train)\n",
    "test_loss_acc=m_lstm.evaluate(input_test,y_test)\n",
    "print(train_loss_acc)\n",
    "print(test_loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 326,273\n",
      "Trainable params: 326,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.4769 - acc: 0.7598\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2899 - acc: 0.8812\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2409 - acc: 0.9069\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2116 - acc: 0.9203\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.1935 - acc: 0.9271\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.1757 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.1625 - acc: 0.9409\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.1479 - acc: 0.9474\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.1432 - acc: 0.9496\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.1338 - acc: 0.9532\n",
      "25000/25000 [==============================] - 30s 1ms/step\n",
      "25000/25000 [==============================] - 31s 1ms/step\n",
      "[0.09908104753017426, 0.9683200120925903]\n",
      "[0.3692723410415649, 0.8626800179481506]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "from keras.models import Sequential\n",
    "m_gru=Sequential()\n",
    "m_gru.add(Embedding(max_features,32))\n",
    "m_gru.add(GRU(32))\n",
    "m_gru.add(Dense(1,activation='sigmoid'))\n",
    "m_gru.summary()\n",
    "m_gru.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "m_gru.fit(input_train,y_train,epochs=10,batch_size=128)\n",
    "train_loss_acc=m_gru.evaluate(input_train,y_train)\n",
    "test_loss_acc=m_gru.evaluate(input_test,y_test)\n",
    "print(train_loss_acc)\n",
    "print(test_loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, None, 32)          8320      \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 353,217\n",
      "Trainable params: 353,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 221s 9ms/step - loss: 0.6021 - acc: 0.6617\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 235s 9ms/step - loss: 0.4202 - acc: 0.8203\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.3588 - acc: 0.8493\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 243s 10ms/step - loss: 0.3242 - acc: 0.8664\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 0.3042 - acc: 0.8780\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.2836 - acc: 0.8891\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 0.2680 - acc: 0.8956\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 0.2574 - acc: 0.9024\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 243s 10ms/step - loss: 0.2444 - acc: 0.9072\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 0.2305 - acc: 0.9150\n",
      "25000/25000 [==============================] - 169s 7ms/step\n",
      "25000/25000 [==============================] - 167s 7ms/step\n",
      "[0.19449921979904175, 0.9313200116157532]\n",
      "[0.3647528399848938, 0.8488399982452393]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU, Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features,32))\n",
    "model.add(LSTM(32, dropout=0.3, recurrent_dropout=0.5, return_sequences=True))\n",
    "model.add(LSTM(64, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "model.fit(input_train,y_train,epochs=10,batch_size=128)\n",
    "train_loss_acc=model.evaluate(input_train,y_train)\n",
    "test_loss_acc=model.evaluate(input_test,y_test)\n",
    "print(train_loss_acc)\n",
    "print(test_loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
